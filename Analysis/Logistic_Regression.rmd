---
title: "Logistic Regression"
author: "Lucia Ronchi Darre"
date: "3/5/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# 1. Load libraries and data

```{r, message = FALSE, warning = FALSE}
library(dplyr)
library(caret)
library(MASS)
library(ggplot2)
library(ggrepel)
library(gains)
library(AUC)
```

Load data:
```{r}
data <- read.csv("tiny_sample.csv")
```

```{r}
data$X <- NULL
data$outlier <- NULL
```

Check structure:
```{r}
str(data)
```

Percentage of people that tip, overall:
```{r}
sum(data[data$tip_flag == 1, "tip_flag"])/nrow(data)
```

Code flags as factors:
```{r}
data[data$tip_flag == 1, "tip_flag"] <- "Yes"
data[data$tip_flag == 0, "tip_flag"] <- "No"
data$tip_flag <- factor(data$tip_flag, levels = c("Yes", "No"))
data$flag_overnight <- factor(data$flag_overnight, levels = c(0,1), labels = c("No", "Yes"))
data$flag_weekend  <- factor(data$flag_weekend , levels = c(0,1), labels = c("No", "Yes"))
```

Check percentage of people that tip, again:
```{r}
sum(data$tip_flag == "Yes")/nrow(data)
```

Change levels of payment type:
```{r}
levels(data$payment_type) <- c("Mobile", "Card", "Cash")
```


Check structure again:
```{r}
str(data)
```

# 2. Split into Train and Test

Split the data into train (70%) and test (30%)
```{r}
# Set seed
set.seed(232323)
# Set train set size (70%)
sample.size <- floor(0.70*nrow(data))
# Create indeces of rows to sample
sample.indeces <- sample.int(n = nrow(data), size = sample.size)
# Create train and test sets according to these sample indices
data.train <- data[sample.indeces, ]
data.test <- data[-sample.indeces, ]
```


# 3. Predict tipping behaviour with logistic regression

Build logistic regression model:
```{r}
reduced.model <- glm(formula = tip_flag ~ duration_seconds + miles + payment_type + speed_dropoff_end  
                     + ride_type + total_no_tip,
                     family = binomial(link=logit),
                     data = data.train)
```

AIC of the reduced model:
```{r}
AIC(reduced.model)
```

Summary of the reduced model:
```{r}
summary(reduced.model)
```


# 4. Gains Chart

Overall proportion of No Tip:
```{r}
round(sum(data.train$tip_flag == "No")/nrow(data.train),2)
```

In order to pick the right threshold, gains chart is calcualted:
```{r}
(gains.train <- gains(actual = as.numeric(data.train$tip_flag) - 1,
                     predicted = reduced.model$fitted.values,
                     groups = 20))
```

# 5. Predictions

Predict based on the reduced model:
```{r}
predicted.class.train <- predict(object = reduced.model, type = c("response"))
predicted.class.train[predicted.class.train >= 0.8] <- "No"
predicted.class.train[predicted.class.train < 0.8] <- "Yes"
predicted.class.train <- factor(predicted.class.train, levels = c("Yes", "No"))
```

Performance Metrics:
```{r}
confusionMatrix(data = predicted.class.train, 
                reference = data.train$tip_flag, 
                positive = "No", 
                mode = "everything")
```

Gains plot:
```{r}
plot(gains.train)
```


# 6. ROC curve

The ROC curve for the Train set is plotted below:
```{r}
# Construct ROC curve
ROC.train <- roc(reduced.model$fitted.values, factor(as.numeric(data.train$tip_flag)-1))
# Get area under the curve
AUC.train <- auc(ROC.train)
plot(ROC.train, main = paste("ROC Curve for Train Set", "\n", 
                             "AUC: ", round(AUC.train, 4)))
```



```{r}
names(ROC.train)
```

```{r}
ggplot(data = data.frame(cutoffs = ROC.train$cutoffs,
                         TPR = ROC.train$tpr,
                         FPR = ROC.train$fpr), 
       aes(x = FPR)) +
  geom_line(aes(y = TPR, color = "TPR")) +
  geom_abline(slope=1, intercept=0, linetype = "dashed", color = "grey") +
  scale_color_manual(values = c("violetred3", "yellowgreen")) +
  labs(title = "ROC Curve", 
       x = "FPR", 
       y = "TPR") + 
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black"),
        axis.text.x = element_text(angle = 0, hjust = 1), 
        plot.title = element_text(hjust = 0.5))
```





# 7. Sensitivity vs Selectivity
The following loop tries out different thresholds for the decision boundary:
```{r}
# Generate iteration variable
i <- 10
# Generate vectors to store results
n <- length(data.train)
predicted.class <- rep(NA, n)
TPR <- rep(NA, i-1)
TNR <- rep(NA, i-1)
# Iterate with different thresholds
for (t in seq(1/i, 1-1/i, 1/i)) {

  # Predict values
  predicted.class <- reduced.model$fitted.values
  predicted.class[predicted.class >= t] <- "No"
  predicted.class[predicted.class < t] <- "Yes"
  predicted.class <- factor(predicted.class, levels = c("Yes", "No"))
  
  # Generate confusion matrix
  (confusion.matrix.train <- table(data.train$tip_flag, predicted.class))
  
  # True positive rate (sensitivity): TP / (TP + FN)
  TPR[t*i] <- confusion.matrix.train[2,2]/(confusion.matrix.train[2,2] + confusion.matrix.train[2,1])
  
  # True negative rate (specificity): TN / (TN + FP)
  TNR[t*i] <- confusion.matrix.train[1,1]/(confusion.matrix.train[1,1] + confusion.matrix.train[1,2])
  
}
```

Plot results:
```{r}
ggplot(data = data.frame(Decision.Boundary = seq(1/i, 1-1/i, 1/i),
                         TPR = round(TPR, 2),
                         TNR = round(TNR, 2)), 
       aes(x = Decision.Boundary)) +
  geom_line(aes(y = TPR, color = "Sensitivity")) +
  geom_line(aes(y = TNR, color = "Specificity")) +
  geom_text_repel(aes(y = TNR, label = TNR), size = 2.5, nudge_y = -0.025) +
  geom_text_repel(aes(y = TPR, label = TPR), size = 2.5, nudge_y = 0.025) +
  geom_vline(xintercept = 0.5, linetype = "dashed", color = "grey") +
  geom_vline(xintercept = 0.8, linetype = "dashed", color = "grey") +
  scale_color_manual(values = c("violetred3", "yellowgreen")) +
  labs(title = "Sensitivity vs Specificity for Train dataset", 
       x = "Decision Boundary", 
       y = "Rate (%)", 
       color = "Metric") + 
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black"),
        axis.text.x = element_text(angle = 0, hjust = 1), 
        plot.title = element_text(hjust = 0.5))
```

# 9. Validation

Predict tipping behaviour in Test set:
```{r}
predicted.class.test <- predict(object = reduced.model, newdata = data.test, type = c("response"))
```

Convert to Yes and No:
```{r}
predicted.class.test[predicted.class.test >= 0.8] <- "No"
predicted.class.test[predicted.class.test < 0.8] <- "Yes"
predicted.class.test <- factor(predicted.class.test, levels = c("Yes", "No"))
```

Performance Metrics for Test set:
```{r}
confusionMatrix(data = predicted.class.test, reference = data.test$tip_flag,
                positive = "No", mode = "everything")
```

Performance Metrics for Train set:
```{r}
confusionMatrix(data = predicted.class.train, reference = data.train$tip_flag,
                positive = "No", mode = "everything")
```









